{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Text Processing\n",
        "\n",
        "In this notebook we are going to go through some text processing teqiniques that we can use to clean our text when doing natural language processing task. We are going to use `spacy` library to perform the following text processing.\n",
        "\n",
        "1. Tokenization\n",
        "2. Part-of-Speech Taging (POS)\n",
        "3. Case Folding\n",
        "4. Stop Words Removal\n",
        "5. Stemming\n",
        "6. Lemmatization\n",
        "7. Named Entity Recognition (NER)\n",
        "8. Parsing\n",
        "\n",
        "\n",
        "First thing first we need to install the latest version of `spacy` by running the following command:"
      ],
      "metadata": {
        "id": "gKRQ10Lb2Iyo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ujQ1Xasp1oSs"
      },
      "outputs": [],
      "source": [
        "!pip install -U spacy==3.* -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check the information about this spacy library by running the following command."
      ],
      "metadata": {
        "id": "XfHCw6gb4c9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzci9TWk1rN1",
        "outputId": "4e8272c9-8abf-4fb7-ab9a-72530cf877e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-14 07:11:59.608219: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-14 07:12:01.172685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    3.6.1                         \n",
            "Location         /usr/local/lib/python3.10/dist-packages/spacy\n",
            "Platform         Linux-5.15.109+-x86_64-with-glibc2.35\n",
            "Python version   3.10.12                       \n",
            "Pipelines        en_core_web_sm (3.6.0)        \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have downloaded `spacy` version `3.*` we must also upgrade the language model `en_core_web_sm`. **`en_core_web_sm`** is a statistical model that we are going to use to process some english sentences. These statistical models can be found at [spacy.io](https://spacy.io/models/en#en_core_web_sm) and they helped us with tokenization, part-of-speech tagging, named entity recognition, etc. First thing first we need to import spacy library as follows:"
      ],
      "metadata": {
        "id": "_NJEb_eg4545"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlwyZ7jo6U1V",
        "outputId": "3ee8a6cc-0c8b-4fbd-f3cb-102975108cfc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-14 07:19:19.400050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xE5UluKF1rol",
        "outputId": "323b2f77-62f8-493e-dc98-6f0462356d31"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.6.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to load the language model `en_core_web_sm` which is the smallest statistical model for english and it can help us to start up so quickly."
      ],
      "metadata": {
        "id": "JR7nHdH21rrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "aFCLki7N1rt_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After loading the model, the `nlp` variable now references a **Language** class instance which contains language-specific rules for various tasks (e.g. tokenization) and a processing pipeline. You can find more about  [here](https://spacy.io/api/language)\n",
        "\n"
      ],
      "metadata": {
        "id": "6EnTcJYj62W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(nlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OQN5UNn1rwG",
        "outputId": "7002c18e-2712-4c0d-d85e-2eadab4a9d74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.lang.en.English"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization\n",
        "\n",
        "This is the processes of converting sentences in a sequence or list of words. Let's take a look at the following sentence.\n",
        "\n",
        "```shell\n",
        "This is a boy.\n",
        "```\n",
        "Tokenizing this sentence can be done using regular python by splitting each word using a space and this results in a list of tokens that looks as follows:\n",
        "\n",
        "```shell\n",
        "[\"This\", \"is\", \"a\", \"boy.\"]\n",
        "```\n",
        "But notice we have a problem here. `boy.` should be two tokens which include the word `boy` and the punctuation mark `.` This problem is solved by spacy. We are going to have a look on how tokenization can be done using `spacy` in an efficient way.\n",
        "\n",
        "When we call the `nlp` object and pass in a string or a sentence. This returns us a `Doc` container object. You can read more about the `Doc` onject container [here](https://spacy.io/api/doc)  "
      ],
      "metadata": {
        "id": "w3pyIGbO7aOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"He didn't want to pay $20 for this book.\"\n",
        "doc = nlp(sent)\n",
        "type(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2MlPyOu1rzR",
        "outputId": "15e2f10a-6675-4905-a359-10cdc7f3948a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can tokenize the above sentence by iterating over the `doc` object as follows:\n"
      ],
      "metadata": {
        "id": "ExAVHBw59BEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print([token.text for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGCS3Or31r1g",
        "outputId": "76f54928-a0cf-4310-d5bf-a818cdfe437c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['He', 'did', \"n't\", 'want', 'to', 'pay', '$', '20', 'for', 'this', 'book', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `Doc` object can be indexed to get individual tokens."
      ],
      "metadata": {
        "id": "F8mvNzec9YYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRt5bZ3f1r4o",
        "outputId": "7edfdbf2-1084-4c1e-a2bd-0ba1b6110b04"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "He"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slicing the `Doc` object returns us a `Span` object. You can learn more about the `Span` object [here.](https://spacy.io/api/token)"
      ],
      "metadata": {
        "id": "erN8d2Bp9mhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc[:3])\n",
        "type(doc[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJC7rWWW1r7m",
        "outputId": "e41b478a-8d90-4720-ca88-2ff0791d4ca3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He didn't\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.span.Span"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can access the index of each token in the doc object as follows:"
      ],
      "metadata": {
        "id": "F_t4gnG5924c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print([(token.i, token.text) for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2v_qzsk1sH_",
        "outputId": "fcf81c59-87ca-4734-d2e2-869c6cfe4bdd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'He'), (1, 'did'), (2, \"n't\"), (3, 'want'), (4, 'to'), (5, 'pay'), (6, '$'), (7, '20'), (8, 'for'), (9, 'this'), (10, 'book'), (11, '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spacy's tokenization is **non-destructive**, which means the original input can be reconstructed from the tokens."
      ],
      "metadata": {
        "id": "e1I6m2Pf1sKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc.text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "47Cb8k5q1sNZ",
        "outputId": "ecd0fce2-18ee-4b8a-b0ef-c28b935afcb2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"He didn't want to pay $20 for this book.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The good thing is `spacy` allows us to tokenize multiple sentences. Let's have a look at the following example:"
      ],
      "metadata": {
        "id": "2j9eyan7--tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"Either the well was very deep, or she fell very slowly, for she\n",
        "had plenty of time as she went down to look about her and to wonder what\n",
        "was going to happen next. First, she tried to look down and make out what\n",
        "she was coming to, but it was too dark to see anything; then she looked at\n",
        "the sides of the well, and noticed that they were filled with cupboards and\n",
        "book-shelves; here and there she saw maps and pictures hung upon pegs.\"\"\"\n",
        "doc = nlp(paragraph)"
      ],
      "metadata": {
        "id": "0n-XSjMa1sQ1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can access the individual sentences using the `doc.sents` as follows:\n",
        "\n",
        "> This will return a list of sentences from our sting."
      ],
      "metadata": {
        "id": "7VYQtubR1sTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[sent for sent in doc.sents]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zXT7BdP1sWW",
        "outputId": "89753d41-a893-4602-d3ef-8f52c3e84ba0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Either the well was very deep, or she fell very slowly, for she \n",
              " had plenty of time as she went down to look about her and to wonder what \n",
              " was going to happen next.,\n",
              " First, she tried to look down and make out what \n",
              " she was coming to, but it was too dark to see anything; then she looked at \n",
              " the sides of the well, and noticed that they were filled with cupboards and \n",
              " book-shelves; here and there she saw maps and pictures hung upon pegs.]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spacy comes with some attributes that can be found [here](https://spacy.io/api/token#attributes) like `is_currency` - which allows us to check if an individual token is a currency symbol or not, `is_bracket`, `is_space` etc. In the following sentence let's filter out the currecy from the sentence. In other terms we want to return the `\"$20\"`"
      ],
      "metadata": {
        "id": "31XYL5yxAYL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"He didn't want to pay $20 for this book.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "\"\".join([t.text for t in doc if t.is_currency or t.is_digit])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "poa9xoYK1sYN",
        "outputId": "4c64a25f-ad42-4646-8bff-d64a01f147a1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'$20'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case Folding\n",
        "\n",
        "`spaCy` performs all these preprocessing steps (except stemming) behind the scenes for us. Inline with its non-destructive policy, the tokens aren't modified directly. Rather, each `Token` object has a number of attributes which can help us get views of your document with these pre-processing steps applied. The attributes a `Token` has can be found [here](https://spacy.io/api/token#attributes).\n",
        "\n",
        "> Let's convert some token's of our sentence to lower case using the `lower_` attribute."
      ],
      "metadata": {
        "id": "Az8S2YHF1sdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"He told Dr. Lovato that he was done with the tests and would post the results shortly.\"\n",
        "doc = nlp(sent)\n",
        "\n",
        "print([token.lower_ for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFDuReOm1sgi",
        "outputId": "8bad1961-7b84-419e-cf1e-a8418f9a7843"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['he', 'told', 'dr.', 'lovato', 'that', 'he', 'was', 'done', 'with', 'the', 'tests', 'and', 'would', 'post', 'the', 'results', 'shortly', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also conditionaly casefold tokens, for example let's say we want to convert the tokens to lower case for all the tokens that are between a sentence and the ones that are at the begining of sentence we will title them."
      ],
      "metadata": {
        "id": "TnObwr0kW5Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print([token if token.is_sent_start else token.lower_ for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVcoaeBL1six",
        "outputId": "c4476969-797a-4304-abc8-ccdcc4eba259"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[He, 'told', 'dr.', 'lovato', 'that', 'he', 'was', 'done', 'with', 'the', 'tests', 'and', 'would', 'post', 'the', 'results', 'shortly', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stopwords\n",
        "\n",
        "`spaCy` comes with some default stopwords. We can check our stopwords list as follows."
      ],
      "metadata": {
        "id": "YUYeM7D3Yx0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = [i for i in nlp.Defaults.stop_words]\n",
        "stop_words[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seHEUyoF1sme",
        "outputId": "9d907aa8-bc8a-42bb-c598-9461b038bb5c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thereupon', 'how', 'perhaps', 'there', 'did']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check the total number of `stopwords` as follows:"
      ],
      "metadata": {
        "id": "IK1ZEoDpZPPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"Default stop words: {}\".format(len(nlp.Defaults.stop_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LjMN35vK1so0",
        "outputId": "41f47632-6b1e-453d-c71e-62a2ced509c2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Default stop words: 326'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatization\n",
        "\n",
        "> Lemmatization is a text pre-processing technique used in natural language processing `(NLP)` models to break a word down to its root meaning to identify similarities.\n",
        "\n",
        "In `spaCy` we can access the lemma of a word using the `lemma_` attribute.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m8TWZp7AZpHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[(t.text, t.lemma_) for t in doc]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybwp7BDd1srM",
        "outputId": "aeac1816-9d8d-48a7-f054-212f97d50b5c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('He', 'he'),\n",
              " ('told', 'tell'),\n",
              " ('Dr.', 'Dr.'),\n",
              " ('Lovato', 'Lovato'),\n",
              " ('that', 'that'),\n",
              " ('he', 'he'),\n",
              " ('was', 'be'),\n",
              " ('done', 'do'),\n",
              " ('with', 'with'),\n",
              " ('the', 'the'),\n",
              " ('tests', 'test'),\n",
              " ('and', 'and'),\n",
              " ('would', 'would'),\n",
              " ('post', 'post'),\n",
              " ('the', 'the'),\n",
              " ('results', 'result'),\n",
              " ('shortly', 'shortly'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that words like `told` are converted to `tell` and words like `results` are converted to `result`.\n",
        "\n",
        "\n",
        "### Stemming\n",
        "\n",
        "> Stemming is the process of reducing a word to its stem that affixes to suffixes and prefixes or to the roots of words known as \"lemmas\".\n",
        "\n",
        "We can use the `nltk` libary to do basic stemming. Let's try to stem our sentence."
      ],
      "metadata": {
        "id": "XOjquFppalnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "metadata": {
        "id": "CQvJkw_V1stF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we are going to initialize the `SnowballStemmer` instance with the `language` as `english`.\n"
      ],
      "metadata": {
        "id": "Vx4eOuehcEBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "[(t.text, stemmer.stem(t.text)) for t in doc]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUUOktO61swN",
        "outputId": "4fcb2135-2c89-4af0-f11b-b857dfacd546"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('He', 'he'),\n",
              " ('told', 'told'),\n",
              " ('Dr.', 'dr.'),\n",
              " ('Lovato', 'lovato'),\n",
              " ('that', 'that'),\n",
              " ('he', 'he'),\n",
              " ('was', 'was'),\n",
              " ('done', 'done'),\n",
              " ('with', 'with'),\n",
              " ('the', 'the'),\n",
              " ('tests', 'test'),\n",
              " ('and', 'and'),\n",
              " ('would', 'would'),\n",
              " ('post', 'post'),\n",
              " ('the', 'the'),\n",
              " ('results', 'result'),\n",
              " ('shortly', 'short'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two major limmitations with stemming:\n",
        "\n",
        "* over-stemming\n",
        "* under-stemming\n",
        "\n",
        "\n",
        "### Part-of-Speech Tagging (POS)\n",
        "\n",
        "\n",
        "spaCy performs Part-of-Speech `(POS)` tagging, Named Entity Recognition `(NER)`, and parsing as part of its default pipeline in the `nlp` object."
      ],
      "metadata": {
        "id": "MK6Den4Pdai4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"John watched an old movie at the cinema.\"\n",
        "doc = nlp(sent)"
      ],
      "metadata": {
        "id": "Lj9IzyLg1szG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`POS` tags can be accessed through the `pos_` attribute"
      ],
      "metadata": {
        "id": "qd6Ebuhs1s2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[(t.text, t.pos_) for t in doc]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAkTOguG1s4d",
        "outputId": "23c2dc7f-fe27-4d43-bb41-dc182d91ff8c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('John', 'PROPN'),\n",
              " ('watched', 'VERB'),\n",
              " ('an', 'DET'),\n",
              " ('old', 'ADJ'),\n",
              " ('movie', 'NOUN'),\n",
              " ('at', 'ADP'),\n",
              " ('the', 'DET'),\n",
              " ('cinema', 'NOUN'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a description for a `POS` tag, we can use `spacy.explain`."
      ],
      "metadata": {
        "id": "6Oand9-E1s7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain('PROPN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L3O9dXwY1s9h",
        "outputId": "705dcba7-6475-4db4-b2c8-fa8eed7a22a6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'proper noun'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `POS` tags above are called **course-grained** tags. We can also access **fine-grained** tags through the `tag_` attribute which provides more detailed information about a token such as its tense and, if a word is a pronoun, what specific type of pronoun it is."
      ],
      "metadata": {
        "id": "FZkkPYVK1tAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[(t.text, t.tag_) for t in doc]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCwe_onvfOrP",
        "outputId": "69129539-b94d-488d-ce3b-49a2e9dc96e9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('John', 'NNP'),\n",
              " ('watched', 'VBD'),\n",
              " ('an', 'DT'),\n",
              " ('old', 'JJ'),\n",
              " ('movie', 'NN'),\n",
              " ('at', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('cinema', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So **NNP** refers specifically to a `singular pronoun`, and **VBD** is a verb in **past tense**."
      ],
      "metadata": {
        "id": "EOR_UjuEfqwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain('NNP'))\n",
        "print(spacy.explain('VBD'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_cihWZPfOuL",
        "outputId": "f1251647-98a1-44f8-a3fe-1fb5f13f7bf7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noun, proper singular\n",
            "verb, past tense\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Named Entity Recognition (NER)\n",
        "\n",
        "There are multiple ways to access named entities. One way is through the `ent_type_` attribute.\n"
      ],
      "metadata": {
        "id": "uE9fU7j1f07M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"Volkswagen is developing an electric sedan which could potentially come to America next fall.\"\n",
        "doc = nlp(sent)"
      ],
      "metadata": {
        "id": "oZ5LDHtyfOyB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[(t.text, t.ent_type_) for t in doc]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebc-jasnfO1C",
        "outputId": "8a9dec42-108a-4b6a-e3f7-b2f1f3295d19"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Volkswagen', 'ORG'),\n",
              " ('is', ''),\n",
              " ('developing', ''),\n",
              " ('an', ''),\n",
              " ('electric', ''),\n",
              " ('sedan', ''),\n",
              " ('which', ''),\n",
              " ('could', ''),\n",
              " ('potentially', ''),\n",
              " ('come', ''),\n",
              " ('to', ''),\n",
              " ('America', 'GPE'),\n",
              " ('next', 'DATE'),\n",
              " ('fall', 'DATE'),\n",
              " ('.', '')]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can explain use the `explain` method to get more information about `spaCy` named entinties or we can access them [here](https://spacy.io/api/annotation#named-entities)"
      ],
      "metadata": {
        "id": "xsjHMVDtggXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain('GPE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TblQTE-vfO4S",
        "outputId": "0cc253eb-dd79-4b90-8f80-c5b8e627809d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Countries, cities, states'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also check if a token is an entity before printing it by checking whether the `ent_type` (note the lack of trailing underscore) attribute is non-zero."
      ],
      "metadata": {
        "id": "bUuW9d2FfO6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print([(t.text, t.ent_type_) for t in doc if t.ent_type != 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGCQOXBVfO9l",
        "outputId": "ac558d7d-0e9e-4508-e846-49c6e9915db4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Volkswagen', 'ORG'), ('America', 'GPE'), ('next', 'DATE'), ('fall', 'DATE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Another way is through the `ents` property of the **Doc** object. Here, we iterate through `ents` and print the entity itself and its label."
      ],
      "metadata": {
        "id": "g5V47PaEhXYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcGv-fbKhXWD",
        "outputId": "206db448-c537-45ff-9616-abc2e46c306d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Volkswagen', 'ORG'), ('America', 'GPE'), ('next fall', 'DATE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Note how `\"next fall\"` is outputted above as a single span when you use `ents`.\n",
        "\n",
        "You can also access the positions of entities as follows:\n"
      ],
      "metadata": {
        "id": "i7Hcp-jghXTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print([(ent.text, ent.label_, ent.start_char, ent.end_char) for ent in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJDZvzW_hXP5",
        "outputId": "41e4a390-5674-46e3-e711-59b9bbf70cb8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Volkswagen', 'ORG', 0, 10), ('America', 'GPE', 75, 82), ('next fall', 'DATE', 83, 92)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`spaCy` is bundled with visualizers for both parsing and named entities and can be accessed [here](https://spacy.io/usage/visualizers)\n",
        "\n",
        "Here, we visualize the entities in our sample sentence."
      ],
      "metadata": {
        "id": "-zefl-Nah6Ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "3dQu6t21h6kD",
        "outputId": "c5021c3d-0d5e-4d0d-d801-30dd0211a562"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Volkswagen\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is developing an electric sedan which could potentially come to \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    America\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    next fall\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For domain-specific corpora, an `NER` tagger may need to be further `fine-tuned`. Here, we may want `The Martian` tagged as a `\"FILM\"` (assuming that's our goal)."
      ],
      "metadata": {
        "id": "MNjnyW7oiTGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"Ridley Scott directed The Martian.\"\n",
        "doc = nlp(sent)\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zVgtxUMNiTCt",
        "outputId": "f989fb25-d4de-40c9-c194-9880a54209bc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ridley Scott\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " directed The \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Martian\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parsing\n",
        "\n",
        "Let's first visualize a parse to make it easier to follow."
      ],
      "metadata": {
        "id": "nYuJNHckizmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"She enrolled in the course at the university.\"\n",
        "doc = nlp(sent)\n",
        "displacy.render(doc, style='dep', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "4dVQ7jbuiS_K",
        "outputId": "d9c67aac-4754-43f4-d20b-823886a85229"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1c54ac92dd00471a93cb08c09de9c67a-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">She</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">enrolled</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">course</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">at</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">university.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1c54ac92dd00471a93cb08c09de9c67a-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1c54ac92dd00471a93cb08c09de9c67a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1c54ac92dd00471a93cb08c09de9c67a-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1c54ac92dd00471a93cb08c09de9c67a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1c54ac92dd00471a93cb08c09de9c67a-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1c54ac92dd00471a93cb08c09de9c67a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1c54ac92dd00471a93cb08c09de9c67a-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1c54ac92dd00471a93cb08c09de9c67a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1c54ac92dd00471a93cb08c09de9c67a-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1c54ac92dd00471a93cb08c09de9c67a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1c54ac92dd00471a93cb08c09de9c67a-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1c54ac92dd00471a93cb08c09de9c67a-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1c54ac92dd00471a93cb08c09de9c67a-0-6\" stroke-width=\"2px\" d=\"M945,177.0 C945,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1c54ac92dd00471a93cb08c09de9c67a-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The visualization above is for a dependency parse (spaCy doesn't come with a constituency parser). For each pair of depencencies, spaCy visualizes the child (pointed to), the head (pointed from), and their relationship (the label arc). You can view the dependency annotations [here](https://spacy.io/api/annotation#dependency-parsing)\n",
        "\n",
        "\n",
        "We can also use `spacy.explain` to get information on a particular annotation."
      ],
      "metadata": {
        "id": "IL8Cq3t9jRZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain('nsubj')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oZB-VeEejbBS",
        "outputId": "c1e2b48e-ae3f-4178-845f-8f945a745925"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nominal subject'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dependency labels themselves can be accessed through the `dep_` attribute."
      ],
      "metadata": {
        "id": "-jnn9sOWjifH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[(t.text, t.dep_) for t in doc]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSIJ6K76jh6G",
        "outputId": "b6349acf-5f8b-4fce-f144-0f54a3d0e31c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('She', 'nsubj'),\n",
              " ('enrolled', 'ROOT'),\n",
              " ('in', 'prep'),\n",
              " ('the', 'det'),\n",
              " ('course', 'pobj'),\n",
              " ('at', 'prep'),\n",
              " ('the', 'det'),\n",
              " ('university', 'pobj'),\n",
              " ('.', 'punct')]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note how the word 'enrolled' is the `ROOT`.\n",
        "\n",
        "\n",
        "But the labels above don't show how the words are related to each other (the arcs). To get a better idea, we can print the head of each dependency."
      ],
      "metadata": {
        "id": "Cm6cbbUIjwta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[(t.text, t.dep_, t.head.text) for t in doc]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvE6m4kVj2fq",
        "outputId": "1f0fece3-d498-4c56-efd9-d3f86f58b631"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('She', 'nsubj', 'enrolled'),\n",
              " ('enrolled', 'ROOT', 'enrolled'),\n",
              " ('in', 'prep', 'enrolled'),\n",
              " ('the', 'det', 'course'),\n",
              " ('course', 'pobj', 'in'),\n",
              " ('at', 'prep', 'course'),\n",
              " ('the', 'det', 'university'),\n",
              " ('university', 'pobj', 'at'),\n",
              " ('.', 'punct', 'enrolled')]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Refs\n",
        "\n",
        "1. https://spacy.io/usage/spacy-101"
      ],
      "metadata": {
        "id": "FyRatHVxB51V"
      }
    }
  ]
}