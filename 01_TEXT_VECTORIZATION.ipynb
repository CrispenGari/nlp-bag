{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorization\n",
        "\n",
        "In the previous notebook we have looked at how we can do text tokenization and some various text processing using `spacy` library. In this notebook we are going to cover some text vectorization, which is the process of converting sequence of words into sequence of numbers. We are going to look at the `Bag of Words (BOW)` and later on we are going to calculate the `cosine similarity` between documents.\n",
        "\n",
        "First thing first we need to install the latest version of `spacy` by running the following command:"
      ],
      "metadata": {
        "id": "gKRQ10Lb2Iyo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ujQ1Xasp1oSs"
      },
      "outputs": [],
      "source": [
        "!pip install -U spacy==3.* -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check the information about this spacy library by running the following command."
      ],
      "metadata": {
        "id": "XfHCw6gb4c9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzci9TWk1rN1",
        "outputId": "a851d881-bcb3-4083-ec8e-a165baa933ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-15 05:51:36.273702: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-15 05:51:37.675279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    3.6.1                         \n",
            "Location         /usr/local/lib/python3.10/dist-packages/spacy\n",
            "Platform         Linux-5.15.109+-x86_64-with-glibc2.35\n",
            "Python version   3.10.12                       \n",
            "Pipelines        en_core_web_sm (3.6.0)        \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have downloaded `spacy` version `3.*` we must also upgrade the language model `en_core_web_sm`. **`en_core_web_sm`** is a statistical model that we are going to use to process some english sentences. These statistical models can be found at [spacy.io](https://spacy.io/models/en#en_core_web_sm) and they helped us with tokenization, part-of-speech tagging, named entity recognition, etc."
      ],
      "metadata": {
        "id": "_NJEb_eg4545"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlwyZ7jo6U1V",
        "outputId": "5e702025-99e7-45aa-8f09-b68793ea0c36"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-15 05:51:50.213236: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-15 05:51:51.632713: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code cell we are going to import all the packages that we are going to use in this notebook."
      ],
      "metadata": {
        "id": "1e06fwB8wC0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from scipy import spatial\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "spacy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xE5UluKF1rol",
        "outputId": "1f9ee6be-0e08-4ab5-fb98-dc08e497839c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.6.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we have the following corpus. Which is basically raw text documents."
      ],
      "metadata": {
        "id": "JR7nHdH21rrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "  \"Red Bull drops hint on F1 engine.\",\n",
        "  \"Honda exits F1, leaving F1 partner Red Bull.\",\n",
        "  \"Hamilton eyes record eighth F1 title.\",\n",
        "  \"Aston Martin announces sponsor.\"\n",
        "]"
      ],
      "metadata": {
        "id": "aFCLki7N1rt_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### BOW\n",
        "A bag-of-words is a representation of text that describes the occurrence of words within a document. This representation includes:\n",
        "\n",
        "* vocabulary of known words\n",
        "* a measure of the presence of known words.\n",
        "\n",
        "> It is called a `“bag”` of words, because any **information about the order or structure of words in the document is discarded**. The model is only concerned with whether known words occur in the document, not where in the document.\n",
        "\n",
        "Before anything, let's go through how the `bow` works from our corpus, asuming that each line is a document.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6EnTcJYj62W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "words = []\n",
        "for sent in corpus:\n",
        "  doc = nlp(sent)\n",
        "  words.extend([token.text.lower() for token in doc if not token.is_punct])\n",
        "vocab = set(words)\n",
        "print(vocab)\n",
        "print(\"Vocab size: {}\".format(len(vocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OQN5UNn1rwG",
        "outputId": "63a4f1d2-989b-42d7-e9d5-b09821bb80d5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eyes', 'eighth', 'martin', 'red', 'partner', 'drops', 'announces', 'sponsor', 'honda', 'hint', 'engine', 'title', 'on', 'bull', 'record', 'leaving', 'exits', 'aston', 'hamilton', 'f1'}\n",
            "Vocab size: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above code cell we have created the set of unique words that are in our `corpus` by casefolding and filtering punctuations. And we have seen that the vocabulary size is `20` which is the total number of unique words in the corpus.\n",
        "\n",
        "Now we can create vectors from each document in our corpus. The simplest scoring method is to mark the presence of words as a boolean value, 0 for absent, 1 for present. This is known as `binary bag of words` and for our first `\"\"Red Bull drops hint on F1 engine.\"\"` sentence in the corpus we might end up with something that looks as follows:"
      ],
      "metadata": {
        "id": "w3pyIGbO7aOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bow(sent, binary=True):\n",
        "  doc = nlp(sent)\n",
        "  tokens = [t.text.lower() for t in doc if not t.is_punct]\n",
        "  indices = [list(vocab).index(t) for t in tokens]\n",
        "  bow = np.zeros(len(vocab), dtype=np.float32)\n",
        "  if binary:\n",
        "    bow[np.array(indices)] = 1\n",
        "  else:\n",
        "     bow[np.array(indices)] = np.array([indices.count(i) for i in indices])\n",
        "  return bow\n",
        "\n",
        "# \"Red Bull drops hint on F1 engine.\"\n",
        "get_bow(corpus[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2MlPyOu1rzR",
        "outputId": "e0085ecf-1851-42a1-fa64-f272ea64984a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_bow(corpus[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZwGkf5o5GlR",
        "outputId": "28155271-6a48-4be0-8355-58cd09cd35b9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
              "       0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Note that there is another `bow` technique which returns the frequecy of that word in a document rather than a binary version which discard how many times the word occur. Let's have a look at the second document in our `corpus`."
      ],
      "metadata": {
        "id": "EFwzzMt46XAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eqWBg9wk6a2y",
        "outputId": "93be8fd5-1e21-4b06-b96e-6519405648e3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Honda exits F1, leaving F1 partner Red Bull.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word `F1` is repeating twice, in the previous example the index of this word was set to `1` in the bow, though it appears twice. We can modify the call of our `get_bow` and set binary to false as follows."
      ],
      "metadata": {
        "id": "68UInDok6eZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_bow(corpus[1], False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVmrM1pK8TeO",
        "outputId": "0917ee9f-8f52-4418-bf0a-48daa90fcd38"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
              "       0., 0., 2.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Fortunately, there are robust libraries which make it easy. From the above corpus we will want to create a basic `Bag of Words (BOW)` representation of our corpus. For that we can use the `scikit-learn` `CountVectorizer` which creates the matrix of token counts from a collection of text documents. You can read more about the CountVectorizer [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform)"
      ],
      "metadata": {
        "id": "ExAVHBw59BEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "bow = vectorizer.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "nGCS3Or31r1g"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can take a look at the features and vocabulary dictionary. Notice the `CountVectorizer` took care of tokenization for us. It also removed punctuation and lower-cased everything"
      ],
      "metadata": {
        "id": "F8mvNzec9YYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRt5bZ3f1r4o",
        "outputId": "3f118ac3-755b-48b4-f5f9-58630e7657e3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['announces', 'aston', 'bull', 'drops', 'eighth', 'engine', 'exits',\n",
              "       'eyes', 'f1', 'hamilton', 'hint', 'honda', 'leaving', 'martin',\n",
              "       'on', 'partner', 'record', 'red', 'sponsor', 'title'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFprZI2P86Oq",
        "outputId": "b5aa740e-6096-4449-e71d-ab5022d92b3b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'red': 17,\n",
              " 'bull': 2,\n",
              " 'drops': 3,\n",
              " 'hint': 10,\n",
              " 'on': 14,\n",
              " 'f1': 8,\n",
              " 'engine': 5,\n",
              " 'honda': 11,\n",
              " 'exits': 6,\n",
              " 'leaving': 12,\n",
              " 'partner': 15,\n",
              " 'hamilton': 9,\n",
              " 'eyes': 7,\n",
              " 'record': 16,\n",
              " 'eighth': 4,\n",
              " 'title': 19,\n",
              " 'aston': 1,\n",
              " 'martin': 13,\n",
              " 'announces': 0,\n",
              " 'sponsor': 18}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specifically, the `CountVectorizer` generates a sparse matrix using an efficient, compressed representation. The sparse matrix object includes a number of useful methods we can explore those methods [here](\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html)"
      ],
      "metadata": {
        "id": "erN8d2Bp9mhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJC7rWWW1r7m",
        "outputId": "71421bbb-0d70-45c9-e6cd-f7bb210bdb83"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse._csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we look at the raw structure, we'll see tuples where the first element represents the document, and the second element represents a token ID. It's then followed by a count of that token. So in the second document (index 1), token 8 (\"f1\") occurs twice."
      ],
      "metadata": {
        "id": "F_t4gnG5924c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2v_qzsk1sH_",
        "outputId": "5f112224-2eaa-4f65-a086-0f755b9d1d76"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 17)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 10)\t1\n",
            "  (0, 14)\t1\n",
            "  (0, 8)\t1\n",
            "  (0, 5)\t1\n",
            "  (1, 17)\t1\n",
            "  (1, 2)\t1\n",
            "  (1, 8)\t2\n",
            "  (1, 11)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 12)\t1\n",
            "  (1, 15)\t1\n",
            "  (2, 8)\t1\n",
            "  (2, 9)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 16)\t1\n",
            "  (2, 4)\t1\n",
            "  (2, 19)\t1\n",
            "  (3, 1)\t1\n",
            "  (3, 13)\t1\n",
            "  (3, 0)\t1\n",
            "  (3, 18)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`CountVectorizer` also supports a custom tokenizer. For every document, it will call your tokenizer and expect a list of tokens returned."
      ],
      "metadata": {
        "id": "e1I6m2Pf1sKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spacy_tokenizer(sent):\n",
        "  return [t.text for t in nlp(sent) if not t.is_punct]"
      ],
      "metadata": {
        "id": "47Cb8k5q1sNZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time, we instantiate `CountVectorizer` with our custom tokenizer (`spacy_tokenizer`), as a kewword arg and also set the `binary` parameter to `True` so we simply get `1s` and `0s` marking token presence rather than token frequency."
      ],
      "metadata": {
        "id": "2j9eyan7--tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer,\n",
        "                              binary=True)\n",
        "bow = vectorizer.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "0n-XSjMa1sQ1"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a dense array representation of our sparse matrix, we use `toarray()` method."
      ],
      "metadata": {
        "id": "vDULtkU_-zoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(bow.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnwZg3tW-uHs",
        "outputId": "710473b9-1113-46f0-db60-6e3aa9cc105a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0]\n",
            " [0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1]\n",
            " [1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bow[0].toarray())\n",
        "print()\n",
        "print(bow[0:2].toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEoo0YL3_AEW",
        "outputId": "c709decc-c490-4414-f6a6-044d4de5d6a5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0]]\n",
            "\n",
            "[[0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine Similarity\n",
        "\n",
        "Now that we have learn how to vectorize our tokens using the `bow` technique. In this section we are going to calculate the `cosine_similarity` between documents.\n",
        "\n",
        "Writing our own cosine similarity function is straight-forward using numpy. There are multiple ways to calculate it using scipy.\n",
        "\n",
        "One way is using the `spatial` package, which is a collection of spatial algorithms and data structures. It has a method to calculate cosine `distance`. To get the cosine `similarity`, we have to substract the distance from 1. You can read more about it [here.](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine)\n"
      ],
      "metadata": {
        "id": "7VYQtubR1sTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc1_vs_doc2 = 1 - spatial.distance.cosine(bow[0].toarray().squeeze(), bow[1].toarray().squeeze())\n",
        "doc1_vs_doc3 = 1 - spatial.distance.cosine(bow[0].toarray().squeeze(), bow[2].toarray().squeeze())\n",
        "doc1_vs_doc4 = 1 - spatial.distance.cosine(bow[0].toarray().squeeze(), bow[3].toarray().squeeze())\n",
        "\n",
        "print(corpus)\n",
        "\n",
        "print(f\"Doc 1 vs Doc 2: {doc1_vs_doc2}\")\n",
        "print(f\"Doc 1 vs Doc 3: {doc1_vs_doc3}\")\n",
        "print(f\"Doc 1 vs Doc 4: {doc1_vs_doc4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zXT7BdP1sWW",
        "outputId": "8ba2e90e-5b85-4c21-f4b1-c2bb12e4555c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Red Bull drops hint on F1 engine.', 'Honda exits F1, leaving F1 partner Red Bull.', 'Hamilton eyes record eighth F1 title.', 'Aston Martin announces sponsor.']\n",
            "Doc 1 vs Doc 2: 0.4285714285714286\n",
            "Doc 1 vs Doc 3: 0.15430334996209194\n",
            "Doc 1 vs Doc 4: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another approach is using scikit-learn's `cosine_similarity` which computes the metric between multiple vectors. Here, we pass it our BOW and get a matrix of cosine similarities between each document and you can read more about it [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)."
      ],
      "metadata": {
        "id": "aW9DPFWdA1R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnj3FWWqA955",
        "outputId": "dcf1ab61-481e-4bac-fa7b-8529674b5c67"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.42857143, 0.15430335, 0.        ],\n",
              "       [0.42857143, 1.        , 0.15430335, 0.        ],\n",
              "       [0.15430335, 0.15430335, 1.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cosine_similarity function can be created using numpy. In the following code cell we are going to create this function. The formular is as follows:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"data:image/png;base64,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\" alt=\"img\"/>\n",
        "</p>\n",
        "\n",
        "The formular can be found in one of my notebooks [here.](https://github.com/CrispenGari/recommentation-algorithms/blob/main/00_ML/00_MOVIE_RECOMMENTATION_SYSTEM/00_MOVIE_RECOMMENTATION_SYSTEM.ipynb) Together with these two links:\n",
        "\n",
        "1. https://numpy.org/doc/stable/reference/generated/numpy.dot.html\n",
        "2. https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html\n",
        "\n",
        "We can come up with the following function:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OTJgyO6gEABH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_sim(a, b):\n",
        "  return np.sum(a * b)/ (np.sqrt(np.sum(np.square(a))) * np.sqrt(np.sum(np.square(a))))"
      ],
      "metadata": {
        "id": "SWxXIZwdDdoQ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc1_vs_doc2 = cos_sim(bow[0].toarray().squeeze(), bow[1].toarray().squeeze())\n",
        "doc1_vs_doc3 = cos_sim(bow[0].toarray().squeeze(), bow[2].toarray().squeeze())\n",
        "doc1_vs_doc4 = cos_sim(bow[0].toarray().squeeze(), bow[3].toarray().squeeze())\n",
        "\n",
        "print(corpus)\n",
        "\n",
        "print(f\"Doc 1 vs Doc 2: {doc1_vs_doc2}\")\n",
        "print(f\"Doc 1 vs Doc 3: {doc1_vs_doc3}\")\n",
        "print(f\"Doc 1 vs Doc 4: {doc1_vs_doc4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI-f0jdyFA9J",
        "outputId": "f7969c5c-1fa7-4d23-fbec-468bb8bbcc96"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Red Bull drops hint on F1 engine.', 'Honda exits F1, leaving F1 partner Red Bull.', 'Hamilton eyes record eighth F1 title.', 'Aston Martin announces sponsor.']\n",
            "Doc 1 vs Doc 2: 0.4285714285714285\n",
            "Doc 1 vs Doc 3: 0.14285714285714285\n",
            "Doc 1 vs Doc 4: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N-Grams\n",
        "\n",
        "The `CountVectorizer` includes an `ngram_range` parameter to generate different `n-grams`. `n_gram` range is specified using a minimum and maximum range. By default, `n_gram range` is set to `(1, 1)` which generates unigrams. Setting it to `(1, 2)` generates both unigrams and bigrams and setting it to `(2, 2)` will generate oly bigrams.\n"
      ],
      "metadata": {
        "id": "F1110PAxBQyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, binary=True,\n",
        "                             ngram_range=(2,2)\n",
        "                             )\n",
        "bigrams = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(vectorizer.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA3cQIO_BvSr",
        "outputId": "1de92e4c-94ca-4678-8708-bef6e50285b7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['announces sponsor' 'aston martin' 'bull drops' 'drops hint' 'eighth f1'\n",
            " 'exits f1' 'eyes record' 'f1 engine' 'f1 leaving' 'f1 partner' 'f1 title'\n",
            " 'hamilton eyes' 'hint on' 'honda exits' 'leaving f1' 'martin announces'\n",
            " 'on f1' 'partner red' 'record eighth' 'red bull']\n",
            "{'red bull': 19, 'bull drops': 2, 'drops hint': 3, 'hint on': 12, 'on f1': 16, 'f1 engine': 7, 'honda exits': 13, 'exits f1': 5, 'f1 leaving': 8, 'leaving f1': 14, 'f1 partner': 9, 'partner red': 17, 'hamilton eyes': 11, 'eyes record': 6, 'record eighth': 18, 'eighth f1': 4, 'f1 title': 10, 'aston martin': 1, 'martin announces': 15, 'announces sponsor': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Term Frequecy - Inverse Document Frequecy (TF-IDF)\n",
        "\n",
        "> _A problem with scoring word frequency is that highly frequent words start to dominate in the document (e.g. larger score), but may not contain as much “informational content” to the model as rarer but perhaps domain specific words._\n",
        "\n",
        "One approach is to rescale the frequency of words by how often they appear in all documents, so that the scores for frequent words like `“the”` that are also frequent across all documents are penalized.\n",
        "\n",
        "* **Term Frequency**: is a scoring of the frequency of the word in the current document.\n",
        "* **Inverse Document Frequency**: is a scoring of how rare the word is across documents.\n",
        "\n",
        "\n",
        "In this section we are going to use a larger [`dataset.scikit-learn.datasets`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets) fetch popular reference datasets online.\n",
        "\n",
        "We'll use the [`20 newsgroups`](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset) dataset, which is a collection of 18,000 newsgroup posts across 20 topics.\n"
      ],
      "metadata": {
        "id": "a3yp47LID8iW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = fetch_20newsgroups(categories=['sci.space'],\n",
        "                            remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "1PV7iHcYHTRn"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check the number of posts in our dataset as follows:"
      ],
      "metadata": {
        "id": "8ujr0D_CIRhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QstHQLRHIV2f",
        "outputId": "7e47c9e6-4140-4716-e0f7-690097c96c59"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "593"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check the first two post as follows:"
      ],
      "metadata": {
        "id": "CIziogu6IYCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.data[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgyV_m_FIcWY",
        "outputId": "e95d19f5-d2c7-4c09-c7bd-a4c5d27adf32"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"\\nAny lunar satellite needs fuel to do regular orbit corrections, and when\\nits fuel runs out it will crash within months.  The orbits of the Apollo\\nmotherships changed noticeably during lunar missions lasting only a few\\ndays.  It is *possible* that there are stable orbits here and there --\\nthe Moon's gravitational field is poorly mapped -- but we know of none.\\n\\nPerturbations from Sun and Earth are relatively minor issues at low\\naltitudes.  The big problem is that the Moon's own gravitational field\\nis quite lumpy due to the irregular distribution of mass within the Moon.\",\n",
              " '\\nGlad to see Griffin is spending his time on engineering rather than on\\nritual purification of the language.  Pity he got stuck with the turkey\\nrather than one of the sensible options.']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we are going to create our custom tokenizer, and we are going to filter out `ner` and `parser` so that this will speed the tokenization process."
      ],
      "metadata": {
        "id": "phFKLfTnIfQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unwanted_pipes = [\"ner\", \"parser\"]\n",
        "\n",
        "def spacy_tokenizer(doc):\n",
        "  with nlp.disable_pipes(*unwanted_pipes):\n",
        "    return [t.lemma_ for t in nlp(doc) if not t.is_punct and not t.is_space and t.is_alpha]"
      ],
      "metadata": {
        "id": "4YgSSsw9I0lr"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like the classes to create raw frequency and binary bag-of-words vectors, scikit-learn includes a similar class called [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)to create TF-IDF vectors from a corpus.\n"
      ],
      "metadata": {
        "id": "MQMiFqdKJEQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)\n",
        "features = vectorizer.fit_transform(corpus.data)\n",
        "print(len(vectorizer.get_feature_names_out()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR6eQKNXJLxO",
        "outputId": "8b2d8b7d-b56d-420a-d82e-ee5d1c9c7afd"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimensions of our feature matrix. X rows (documents) by Y columns (tokens).\n"
      ],
      "metadata": {
        "id": "UQkHYbyeJWRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmvt3X9EJTV9",
        "outputId": "e3018715-77ca-4c1b-cc56-fec53b31faab"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(593, 9440)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What the encoding of the first document looks like in sparse format."
      ],
      "metadata": {
        "id": "INQymQwTJY0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(features[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c00shsDJbsy",
        "outputId": "345a3b20-858c-44de-9f87-42fe064f3427"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 5064)\t0.10452754121963853\n",
            "  (0, 2351)\t0.12747025764625855\n",
            "  (0, 4340)\t0.15331700873692364\n",
            "  (0, 2459)\t0.10862435105627101\n",
            "  (0, 4916)\t0.17102715751031994\n",
            "  (0, 6702)\t0.09940033595823265\n",
            "  (0, 5982)\t0.10183554382071024\n",
            "  (0, 6514)\t0.08455482269873241\n",
            "  (0, 896)\t0.0892999596249832\n",
            "  (0, 316)\t0.1109487112663238\n",
            "  (0, 4896)\t0.08247641364333849\n",
            "  (0, 628)\t0.051044670776703174\n",
            "  (0, 4368)\t0.10270174012167517\n",
            "  (0, 5274)\t0.13259746290766442\n",
            "  (0, 6908)\t0.12524708704889775\n",
            "  (0, 2494)\t0.07376562213268434\n",
            "  (0, 8105)\t0.09513204666042695\n",
            "  (0, 3287)\t0.051874685324429695\n",
            "  (0, 6181)\t0.1390186329543497\n",
            "  (0, 5652)\t0.11219531673533985\n",
            "  (0, 4589)\t0.06321728493925476\n",
            "  (0, 9158)\t0.06158004812009137\n",
            "  (0, 1141)\t0.048918909156680825\n",
            "  (0, 5023)\t0.12320196834845284\n",
            "  (0, 6354)\t0.15331700873692364\n",
            "  :\t:\n",
            "  (0, 1344)\t0.09036471134545682\n",
            "  (0, 5403)\t0.17102715751031994\n",
            "  (0, 451)\t0.10452754121963853\n",
            "  (0, 5790)\t0.0991335109087398\n",
            "  (0, 8368)\t0.20402991671500817\n",
            "  (0, 5377)\t0.10099775257415368\n",
            "  (0, 9288)\t0.19295422430071502\n",
            "  (0, 1901)\t0.13560685996352737\n",
            "  (0, 9251)\t0.059876060572569896\n",
            "  (0, 4372)\t0.07654889960067542\n",
            "  (0, 5938)\t0.06437012757347277\n",
            "  (0, 7214)\t0.09717716536087184\n",
            "  (0, 4381)\t0.07522603925785983\n",
            "  (0, 9214)\t0.07158981085158692\n",
            "  (0, 371)\t0.10544208975368659\n",
            "  (0, 1846)\t0.13560685996352737\n",
            "  (0, 5882)\t0.21555560387140033\n",
            "  (0, 6885)\t0.13560685996352737\n",
            "  (0, 2372)\t0.04343313069714861\n",
            "  (0, 8491)\t0.06551548062794398\n",
            "  (0, 3300)\t0.1988006719164653\n",
            "  (0, 5546)\t0.07463181843364929\n",
            "  (0, 7281)\t0.08827780957141772\n",
            "  (0, 4918)\t0.17756754701430466\n",
            "  (0, 426)\t0.07007152202826399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The similarity measuring techniques we learned in the last section can be used here in the same way. In effect, we can query our data using this sequence:\n",
        "\n",
        "1. `Transform` our query using the same vocabulary from our `fit` step on our corpus.\n",
        "2. `Calculate` the pairwise cosine similarities between each document in our corpus and our query.\n",
        "3. `Sort` them in descending order by score."
      ],
      "metadata": {
        "id": "x3jX2FvSJm3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = [\"lunar orbit\"]\n",
        "query_tfidf = vectorizer.transform(query)\n",
        "query_tfidf.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVSYRiz4J1HT",
        "outputId": "daff57cc-81c6-488f-f7df-3f9536c37c50"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarities = cosine_similarity(features, query_tfidf).flatten()\n"
      ],
      "metadata": {
        "id": "UcCFbfgCJ7UQ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our list of cosine similarities, we can use this utility function to return the indices of the top k documents with the highest cosine similarities."
      ],
      "metadata": {
        "id": "DLb6jIT4KH-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k(arr, k):\n",
        "  kth_largest = (k + 1) * -1\n",
        "  return np.argsort(arr)[:kth_largest:-1]"
      ],
      "metadata": {
        "id": "ng9HFz9VKVR0"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_related_indices = top_k(cosine_similarities, 5)\n",
        "top_related_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_oufpHzKWrq",
        "outputId": "dfd0075b-613f-4f1b-8385-9c790539106f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([249, 108,   0, 312, 509])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at their respective cosine similarities."
      ],
      "metadata": {
        "id": "NyvIhbvNKhO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarities[top_related_indices])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jApOyIPmKiAJ",
        "outputId": "c580aaeb-424c-45df-9f2e-5b83dd25401f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.47855355 0.4292246  0.2736328  0.19486489 0.19125175]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top match."
      ],
      "metadata": {
        "id": "j9fPsC1hKkH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus.data[top_related_indices[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ove5z7FOKnn_",
        "outputId": "4469a74e-62db-4409-f477-2234c5b4c59a"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Actually, Hiten wasn't originally intended to go into lunar orbit at all,\n",
            "so it indeed didn't have much fuel on hand.  The lunar-orbit mission was\n",
            "an afterthought, after Hagoromo (a tiny subsatellite deployed by Hiten\n",
            "during a lunar flyby) had a transmitter failure and its proper insertion\n",
            "into lunar orbit couldn't be positively confirmed.\n",
            "\n",
            "It should be noted that the technique does have disadvantages.  It takes\n",
            "a long time, and you end up with a relatively inconvenient lunar orbit.\n",
            "If you want something useful like a low circular polar orbit, you do have\n",
            "to plan to expend a certain amount of fuel, although it is reduced from\n",
            "what you'd need for the brute-force approach.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limitations of BoW\n",
        "\n",
        "Bag of words suffers from:\n",
        "\n",
        "* `Vocabulary`: The vocabulary requires careful design, most specifically in order to manage the size, which impacts the sparsity of the document representations.\n",
        "* `Sparsity`: Sparse representations are harder to model both for computational reasons (space and time complexity) and also for information reasons, where the challenge is for the models to harness so little information in such a large representational space.\n",
        "* `Meaning`: Discarding word order ignores the context, and in turn meaning of words in the document (semantics). Context and meaning can offer a lot to the model, that if modeled could tell the difference between the same words differently arranged (“this is interesting” vs “is this interesting”), synonyms (“old bike” vs “used bike”), and much more.\n",
        "\n"
      ],
      "metadata": {
        "id": "Hv2A42n5G1gE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Refs\n",
        "\n",
        "1. https://spacy.io/usage/spacy-101\n",
        "2. https://machinelearningmastery.com/gentle-introduction-bag-words-model/\n",
        "3. https://docs.scipy.org/doc/scipy/reference/spatial.html"
      ],
      "metadata": {
        "id": "FyRatHVxB51V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pigYIMLzyBWD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}